# -*- coding: utf-8 -*-
"""Welcome To Colaboratory

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb

<p><img alt="Colaboratory logo" height="45px" src="/img/colab_favicon.ico" align="left" hspace="10px" vspace="0px"></p>

<h1>What is Colaboratory?</h1>

Colaboratory, or "Colab" for short, allows you to write and execute Python in your browser, with 
- Zero configuration required
- Free access to GPUs
- Easy sharing

Whether you're a **student**, a **data scientist** or an **AI researcher**, Colab can make your work easier. Watch [Introduction to Colab](https://www.youtube.com/watch?v=inN8seMm7UI) to learn more, or just get started below!

## **Getting started**

The document you are reading is not a static web page, but an interactive environment called a **Colab notebook** that lets you write and execute code.

For example, here is a **code cell** with a short Python script that computes a value, stores it in a variable, and prints the result:
"""

seconds_in_a_day = 24 * 60 * 60
seconds_in_a_day

"""To execute the code in the above cell, select it with a click and then either press the play button to the left of the code, or use the keyboard shortcut "Command/Ctrl+Enter". To edit the code, just click the cell and start editing.

Variables that you define in one cell can later be used in other cells:
"""

seconds_in_a_week = 7 * seconds_in_a_day
seconds_in_a_week

"""Colab notebooks allow you to combine **executable code** and **rich text** in a single document, along with **images**, **HTML**, **LaTeX** and more. When you create your own Colab notebooks, they are stored in your Google Drive account. You can easily share your Colab notebooks with co-workers or friends, allowing them to comment on your notebooks or even edit them. To learn more, see [Overview of Colab](/notebooks/basic_features_overview.ipynb). To create a new Colab notebook you can use the File menu above, or use the following link: [create a new Colab notebook](http://colab.research.google.com#create=true).

Colab notebooks are Jupyter notebooks that are hosted by Colab. To learn more about the Jupyter project, see [jupyter.org](https://www.jupyter.org).

## Data science

With Colab you can harness the full power of popular Python libraries to analyze and visualize data. The code cell below uses **numpy** to generate some random data, and uses **matplotlib** to visualize it. To edit the code, just click the cell and start editing.
"""

import numpy as np
from matplotlib import pyplot as plt

ys = 200 + np.random.randn(100)
x = [x for x in range(len(ys))]

plt.plot(x, ys, '-')
plt.fill_between(x, ys, 195, where=(ys > 195), facecolor='g', alpha=0.6)

plt.title("Sample Visualization")
plt.show()

"""You can import your own data into Colab notebooks from your Google Drive account, including from spreadsheets, as well as from Github and many other sources. To learn more about importing data, and how Colab can be used for data science, see the links below under [Working with Data](#working-with-data).

## Machine learning

With Colab you can import an image dataset, train an image classifier on it, and evaluate the model, all in just [a few lines of code](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb). Colab notebooks execute code on Google's cloud servers, meaning you can leverage the power of Google hardware, including [GPUs and TPUs](#using-accelerated-hardware), regardless of the power of your machine. All you need is a browser.

Colab is used extensively in the machine learning community with applications including:
- Getting started with TensorFlow
- Developing and training neural networks
- Experimenting with TPUs
- Disseminating AI research
- Creating tutorials

To see sample Colab notebooks that demonstrate machine learning applications, see the [machine learning examples](#machine-learning-examples) below.

## More Resources

### Working with Notebooks in Colab
- [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)
- [Guide to Markdown](/notebooks/markdown_guide.ipynb)
- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)
- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)
- [Interactive forms](/notebooks/forms.ipynb)
- [Interactive widgets](/notebooks/widgets.ipynb)
- <img src="/img/new.png" height="20px" align="left" hspace="4px" alt="New"></img>
 [TensorFlow 2 in Colab](/notebooks/tensorflow_version.ipynb)

<a name="working-with-data"></a>
### Working with Data
- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb) 
- [Charts: visualizing data](/notebooks/charts.ipynb)
- [Getting started with BigQuery](/notebooks/bigquery.ipynb)

### Machine Learning Crash Course
These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.
- [Intro to Pandas](/notebooks/mlcc/intro_to_pandas.ipynb)
- [Tensorflow concepts](/notebooks/mlcc/tensorflow_programming_concepts.ipynb)
- [First steps with TensorFlow](/notebooks/mlcc/first_steps_with_tensor_flow.ipynb)
- [Intro to neural nets](/notebooks/mlcc/intro_to_neural_nets.ipynb)
- [Intro to sparse data and embeddings](/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb)

<a name="using-accelerated-hardware"></a>
### Using Accelerated Hardware
- [TensorFlow with GPUs](/notebooks/gpu.ipynb)
- [TensorFlow with TPUs](/notebooks/tpu.ipynb)

<a name="machine-learning-examples"></a>

## Machine Learning Examples

To see end-to-end examples of the interactive machine learning analyses that Colaboratory makes possible, check out these  tutorials using models from [TensorFlow Hub](https://tfhub.dev).

A few featured examples:

- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.
- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.
- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.
- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.
- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.
"""

import numpy as np
import pandas as pd
import datetime
from scipy.stats import skew
from scipy.fftpack import fft
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_validate,train_test_split,StratifiedKFold
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
import pickle

mydateparser_p1 = lambda x: pd.datetime.strptime(x, '%m/%d/%Y')
RAW_INSULIN_DATA_P1 = pd.read_csv('InsulinData.csv', parse_dates=['Date'], date_parser=mydateparser_p1)
RAW_INSULIN_DATA_P1 = RAW_INSULIN_DATA_P1[["Date", "Time", "BWZ Carb Input (grams)"]]  
RAW_INSULIN_DATA_P1['Time'] = pd.to_timedelta(RAW_INSULIN_DATA_P1["Time"])
#print(RAW_INSULIN_DATA)
bool_series = pd.notnull(RAW_INSULIN_DATA_P1["BWZ Carb Input (grams)"])
INSULIN_DATA_WITH_ZEROS_P1 = RAW_INSULIN_DATA_P1[bool_series]
INSULIN_DATA_P1 = INSULIN_DATA_WITH_ZEROS_P1[INSULIN_DATA_WITH_ZEROS_P1["BWZ Carb Input (grams)"]>0]
#pd.set_option('display.max_rows', INSULIN_DATA.shape[0]+1)
INSULIN_DATA_P1['Date_Time'] = INSULIN_DATA_P1['Date'] + INSULIN_DATA_P1['Time']
#print(INSULIN_DATA_P1)
INSULIN_DATA_P1.dtypes


MEAL_SORTED_INSULIN_DATA_P1 = pd.DataFrame()
NO_MEAL_SORTED_INSULIN_DATA_P1 = pd.DataFrame()

total_rows_P1 = INSULIN_DATA_P1.shape[0]
index_P1=total_rows_P1-1
df1_P1 = pd.DataFrame()
while index_P1>=0:
    data_arr_P1 = INSULIN_DATA_P1.iloc[index_P1].values
    df1_P1[index_P1] = data_arr_P1[::-1]
    index_P1 = index_P1 - 1

MEAL_SORTED_INSULIN_DATA_P1 = MEAL_SORTED_INSULIN_DATA_P1.append(df1_P1.transpose())
#MEAL_SORTED_INSULIN_DATA_P1.interpolate(method='linear', inplace=True)
MEAL_SORTED_INSULIN_DATA_P1 = MEAL_SORTED_INSULIN_DATA_P1[[3, 2, 1, 0]]
MEAL_SORTED_INSULIN_DATA_P1 = MEAL_SORTED_INSULIN_DATA_P1.rename(columns={3: 'Date', 2: 'Time', 1: 'Carb_Value', 0: 'Date_Time'})
pd.set_option('display.max_columns', None)
#print('MEAL_SORTED')
#print(MEAL_SORTED_INSULIN_DATA_P1)

total_rows_4_P1 = INSULIN_DATA_P1.shape[0]
index_4_P1=total_rows_4_P1-1
df2_P1 = pd.DataFrame()
while index_4_P1>=0:
    data_arr_1_P1 = INSULIN_DATA_P1.iloc[index_4_P1].values
    df2_P1[index_4_P1] = data_arr_1_P1[::-1]
    index_4_P1 = index_4_P1 - 1

NO_MEAL_SORTED_INSULIN_DATA_P1 = NO_MEAL_SORTED_INSULIN_DATA_P1.append(df2_P1.transpose())
#NO_MEAL_SORTED_INSULIN_DATA_P1.interpolate(method='linear', inplace=True)
NO_MEAL_SORTED_INSULIN_DATA_P1 = NO_MEAL_SORTED_INSULIN_DATA_P1[[3, 2, 1, 0]]
NO_MEAL_SORTED_INSULIN_DATA_P1 = NO_MEAL_SORTED_INSULIN_DATA_P1.rename(columns={3: 'Date', 2: 'Time', 1: 'Carb_Value', 0: 'Date_Time'})
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', NO_MEAL_SORTED_INSULIN_DATA_P1.shape[0]+1)
#print(NO_MEAL_SORTED_INSULIN_DATA_P1)


Meal_Indices_to_be_dropped_P1=list()
total_rows_1_P1 = MEAL_SORTED_INSULIN_DATA_P1.shape[0]
index_1_P1=total_rows_1_P1-1
required_time_diff_P1 = pd.to_timedelta('0 days 02:00:00')
for i in range(0, total_rows_1_P1-1):
  j = i+1
  a = MEAL_SORTED_INSULIN_DATA_P1['Date_Time'][index_1_P1-i]
  #print(a)
  b = MEAL_SORTED_INSULIN_DATA_P1['Date_Time'][index_1_P1-j]
  #print(b)
  time_diff_P1 = b-a
  if(time_diff_P1<required_time_diff_P1): 
    Meal_Indices_to_be_dropped_P1.insert(0,index_1_P1-i)
    #print(index_1-i)
#print(Meal_Indices_to_be_dropped_P1)

for index_1_P1 in Meal_Indices_to_be_dropped_P1:
  MEAL_SORTED_INSULIN_DATA_P1 = MEAL_SORTED_INSULIN_DATA_P1.drop(index_1_P1)

MEAL_SORTED_INSULIN_DATA_P1 = MEAL_SORTED_INSULIN_DATA_P1.reset_index(drop=True)
pd.set_option('display.max_rows', MEAL_SORTED_INSULIN_DATA_P1.shape[0]+1)
#print(MEAL_SORTED_INSULIN_DATA_P1)

NoMeal_Indices_to_be_dropped_P1=list()
total_rows_5_P1 = NO_MEAL_SORTED_INSULIN_DATA_P1.shape[0]
index_5_P1=total_rows_5_P1-1
required_time_diff_P1 = pd.to_timedelta('0 days 04:00:00')
for i in range(0, total_rows_5_P1-1):
  for j in range(i+1, total_rows_5_P1):
    a = NO_MEAL_SORTED_INSULIN_DATA_P1['Date_Time'][index_5_P1-i]
    #print(a)
    b = NO_MEAL_SORTED_INSULIN_DATA_P1['Date_Time'][index_5_P1-j]
    #print(b)
    time_diff_P1 = b-a
    if(time_diff_P1<required_time_diff_P1): 
      NoMeal_Indices_to_be_dropped_P1.insert(0,index_5_P1-j)
    else:
      break  
      #print(index_1-i)
  #print(len(Indices_to_be_dropped))
NoMeal_Indices_to_be_dropped_P1 = list(set(NoMeal_Indices_to_be_dropped_P1))  
#print(NoMeal_Indices_to_be_dropped)
for index_5_P1 in NoMeal_Indices_to_be_dropped_P1:
  NO_MEAL_SORTED_INSULIN_DATA_P1 = NO_MEAL_SORTED_INSULIN_DATA_P1.drop(index_5_P1)

NO_MEAL_SORTED_INSULIN_DATA_P1 = NO_MEAL_SORTED_INSULIN_DATA_P1.reset_index(drop=True)
pd.set_option('display.max_rows', NO_MEAL_SORTED_INSULIN_DATA_P1.shape[0]+1)
#print(NO_MEAL_SORTED_INSULIN_DATA_P1)

mydateparser_P1 = lambda x: pd.datetime.strptime(x, '%m/%d/%Y')
RAW_CGM_DATA_P1 = pd.read_csv('CGMData.csv', parse_dates=['Date'], date_parser=mydateparser_P1)
RAW_CGM_DATA_P1 = RAW_CGM_DATA_P1[["Date", "Time", "Sensor Glucose (mg/dL)"]]  
RAW_CGM_DATA_P1['Time'] = pd.to_timedelta(RAW_CGM_DATA_P1["Time"])
RAW_CGM_DATA_P1['Date_Time'] = RAW_CGM_DATA_P1['Date'] + RAW_CGM_DATA_P1['Time']


CGM_MEAL_VECTOR_P1 = pd.DataFrame(columns=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29])
#CGM_MEAL_VECTOR = RAW_CGM_DATA[index_2-100:index_2-50]
#print(CGM_MEAL_VECTOR)

#print(MEAL_SORTED_INSULIN_DATA['Date_Time'][0])
y_P1 = MEAL_SORTED_INSULIN_DATA_P1['Date_Time'][0]
#print(y)
time_list_P1 = []
time_list_P1 = RAW_CGM_DATA_P1['Date_Time'].tolist()
time_list_P1.reverse()
#print(time_list)
glucose_list_P1 = RAW_CGM_DATA_P1['Sensor Glucose (mg/dL)'].tolist()
glucose_list_P1.reverse()
#print(glucose_list)
#print(len(time_list))
#print(len(glucose_list))


i = 0
for j in range(0,len(MEAL_SORTED_INSULIN_DATA_P1['Date_Time'])):
  y_P1 = MEAL_SORTED_INSULIN_DATA_P1['Date_Time'][j]
  temp_P1 = []
  while time_list_P1[i]<y_P1  and i<len(time_list_P1):
    i=i+1
  if i>=len(time_list_P1):
    break
  temp_P1 = glucose_list_P1[i-6:i+24]
  #if(time_list[i-5]>=y-required_time_30 and time_list[i+25]<=y+required_time_2):
  if(len(temp_P1)==30):
    CGM_MEAL_VECTOR_P1.loc[len(CGM_MEAL_VECTOR_P1), :] = temp_P1
  #print(CGM_MEAL_VECTOR)
  i = i+25
#print(CGM_MEAL_VECTOR)

CGM_MEAL_VECTOR_P1 = CGM_MEAL_VECTOR_P1.dropna()      
CGM_MEAL_VECTOR_P1 = CGM_MEAL_VECTOR_P1.reset_index(drop=True)
CGM_MEAL_VECTOR_P1 = CGM_MEAL_VECTOR_P1.head(n=200)
#print(CGM_MEAL_VECTOR_P1);


CGM_NO_MEAL_VECTOR_P1 = pd.DataFrame(columns=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23])
#CGM_MEAL_VECTOR = RAW_CGM_DATA[index_2-100:index_2-50]
#print(CGM_MEAL_VECTOR)

#print(NO_MEAL_SORTED_INSULIN_DATA_P1['Date_Time'][0])
y_1_P1 = NO_MEAL_SORTED_INSULIN_DATA_P1['Date_Time'][0]
#print(y_1_P1)
time_list_1_P1 = []
time_list_1_P1 = RAW_CGM_DATA_P1['Date_Time'].tolist()
time_list_1_P1.reverse()
#print(time_list_1_P1)
glucose_list_1_P1 = RAW_CGM_DATA_P1['Sensor Glucose (mg/dL)'].tolist()
glucose_list_1_P1.reverse()
#print(glucose_list_1_P1)
#print(len(time_list_1_P1))
#print(len(glucose_list_1_P1))

required_time_30_P1 = pd.to_timedelta('0 days 00:30:00')
required_time_2_P1 = pd.to_timedelta('0 days 02:00:00')
i = 0
for j in range(0,len(NO_MEAL_SORTED_INSULIN_DATA_P1['Date_Time'])):
  y_1 = NO_MEAL_SORTED_INSULIN_DATA_P1['Date_Time'][j]
  temp_1_P1 = []
  while time_list_1_P1[i]<y_1  and i<len(time_list_1_P1):
    i=i+1
  if i>=len(time_list_1_P1):
    break
  temp_1_P1 = glucose_list_1_P1[i:i+24]
  if(len(temp_1_P1)==24):
    CGM_NO_MEAL_VECTOR_P1.loc[len(CGM_NO_MEAL_VECTOR_P1), :] = temp_1_P1
  i = i+25
#print(CGM_NO_MEAL_VECTOR_P1)

CGM_NO_MEAL_VECTOR_P1 = CGM_NO_MEAL_VECTOR_P1.dropna()      
CGM_NO_MEAL_VECTOR_P1 = CGM_NO_MEAL_VECTOR_P1.reset_index(drop=True)
CGM_NO_MEAL_VECTOR_P1 = CGM_NO_MEAL_VECTOR_P1.head(n=250)
#print(CGM_NO_MEAL_VECTOR_P1)

mydateparser_p2 = lambda x: pd.datetime.strptime(x, '%m/%d/%Y')
RAW_INSULIN_DATA_P2 = pd.read_csv('InsulinAndMealIntake670GPatient3.csv', parse_dates=['Date'], date_parser=mydateparser_p2)
RAW_INSULIN_DATA_P2 = RAW_INSULIN_DATA_P2[["Date", "Time", "BWZ Carb Input (grams)"]]  
RAW_INSULIN_DATA_P2['Time'] = pd.to_timedelta(RAW_INSULIN_DATA_P2["Time"])
#print(RAW_INSULIN_DATA)
bool_series_P2 = pd.notnull(RAW_INSULIN_DATA_P2["BWZ Carb Input (grams)"])
INSULIN_DATA_WITH_ZEROS_P2 = RAW_INSULIN_DATA_P2[bool_series_P2]
INSULIN_DATA_P2 = INSULIN_DATA_WITH_ZEROS_P2[INSULIN_DATA_WITH_ZEROS_P2["BWZ Carb Input (grams)"]>0]
#pd.set_option('display.max_rows', INSULIN_DATA.shape[0]+1)
INSULIN_DATA_P2['Date_Time'] = INSULIN_DATA_P2['Date'] + INSULIN_DATA_P2['Time']
pd.set_option('display.max_rows', INSULIN_DATA_P2.shape[0]+1)
#print(INSULIN_DATA_P2)
INSULIN_DATA_P2.dtypes


MEAL_SORTED_INSULIN_DATA_P2 = pd.DataFrame()
NO_MEAL_SORTED_INSULIN_DATA_P2 = pd.DataFrame()

total_rows_P2 = INSULIN_DATA_P2.shape[0]
index_P2=total_rows_P2-1
df1_P2 = pd.DataFrame()
while index_P2>=0:
    data_arr_P2 = INSULIN_DATA_P2.iloc[index_P2].values
    df1_P2[index_P2] = data_arr_P2[::-1]
    index_P2 = index_P2 - 1

MEAL_SORTED_INSULIN_DATA_P2 = MEAL_SORTED_INSULIN_DATA_P2.append(df1_P2.transpose())
MEAL_SORTED_INSULIN_DATA_P2.interpolate(method='linear', inplace=True)
MEAL_SORTED_INSULIN_DATA_P2 = MEAL_SORTED_INSULIN_DATA_P2[[3, 2, 1, 0]]
MEAL_SORTED_INSULIN_DATA_P2 = MEAL_SORTED_INSULIN_DATA_P2.rename(columns={3: 'Date', 2: 'Time', 1: 'Carb_Value', 0: 'Date_Time'})
pd.set_option('display.max_columns', None)
#print(MEAL_SORTED_INSULIN_DATA_P2)

total_rows_4_P2 = INSULIN_DATA_P2.shape[0]
index_4_P2=total_rows_4_P2-1
df2_P2 = pd.DataFrame()
while index_4_P2>=0:
    data_arr_1_P2 = INSULIN_DATA_P2.iloc[index_4_P2].values
    df2_P2[index_4_P2] = data_arr_1_P2[::-1]
    index_4_P2 = index_4_P2 - 1

NO_MEAL_SORTED_INSULIN_DATA_P2 = NO_MEAL_SORTED_INSULIN_DATA_P2.append(df2_P2.transpose())
NO_MEAL_SORTED_INSULIN_DATA_P2.interpolate(method='linear', inplace=True)
NO_MEAL_SORTED_INSULIN_DATA_P2 = NO_MEAL_SORTED_INSULIN_DATA_P2[[3, 2, 1, 0]]
NO_MEAL_SORTED_INSULIN_DATA_P2 = NO_MEAL_SORTED_INSULIN_DATA_P2.rename(columns={3: 'Date', 2: 'Time', 1: 'Carb_Value', 0: 'Date_Time'})
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', NO_MEAL_SORTED_INSULIN_DATA_P2.shape[0]+1)
#print(NO_MEAL_SORTED_INSULIN_DATA)


Meal_Indices_to_be_dropped_P2=list()
total_rows_1_P2 = MEAL_SORTED_INSULIN_DATA_P2.shape[0]
index_1_P2=total_rows_1_P2-1
required_time_diff_P2 = pd.to_timedelta('0 days 02:00:00')
for i in range(0, total_rows_1_P2-1):
  j = i+1
  a = MEAL_SORTED_INSULIN_DATA_P2['Date_Time'][index_1_P2-i]
  #print(a)
  b = MEAL_SORTED_INSULIN_DATA_P2['Date_Time'][index_1_P2-j]
  #print(b)
  time_diff_P2 = b-a
  if(time_diff_P2<required_time_diff_P2): 
    Meal_Indices_to_be_dropped_P2.insert(0,index_1_P2-i)
    #print(index_1-i)
#print(Meal_Indices_to_be_dropped_P2)

for index_1_P2 in Meal_Indices_to_be_dropped_P2:
  MEAL_SORTED_INSULIN_DATA_P2 = MEAL_SORTED_INSULIN_DATA_P2.drop(index_1_P2)

MEAL_SORTED_INSULIN_DATA_P2 = MEAL_SORTED_INSULIN_DATA_P2.reset_index(drop=True)
pd.set_option('display.max_rows', MEAL_SORTED_INSULIN_DATA_P2.shape[0]+1)
#print(MEAL_SORTED_INSULIN_DATA_P2)

NoMeal_Indices_to_be_dropped_P2=list()
total_rows_5_P2 = NO_MEAL_SORTED_INSULIN_DATA_P2.shape[0]
index_5_P2=total_rows_5_P2-1
required_time_diff_P2 = pd.to_timedelta('0 days 04:00:00')
for i in range(0, total_rows_5_P2-1):
  for j in range(i+1, total_rows_5_P2):
    a = NO_MEAL_SORTED_INSULIN_DATA_P2['Date_Time'][index_5_P2-i]
    #print(a)
    b = NO_MEAL_SORTED_INSULIN_DATA_P2['Date_Time'][index_5_P2-j]
    #print(b)
    time_diff_P2 = b-a
    if(time_diff_P2<required_time_diff_P2): 
      NoMeal_Indices_to_be_dropped_P2.insert(0,index_5_P2-j)
    else:
      break  
      #print(index_1-i)
  #print(len(Indices_to_be_dropped))
NoMeal_Indices_to_be_dropped_P2 = list(set(NoMeal_Indices_to_be_dropped_P2))  
#print(NoMeal_Indices_to_be_dropped)
for index_5_P2 in NoMeal_Indices_to_be_dropped_P2:
  NO_MEAL_SORTED_INSULIN_DATA_P2 = NO_MEAL_SORTED_INSULIN_DATA_P2.drop(index_5_P2)

NO_MEAL_SORTED_INSULIN_DATA_P2 = NO_MEAL_SORTED_INSULIN_DATA_P2.reset_index(drop=True)
pd.set_option('display.max_rows', NO_MEAL_SORTED_INSULIN_DATA_P2.shape[0]+1)
#print(NO_MEAL_SORTED_INSULIN_DATA_P2)

mydateparser_P2 = lambda x: pd.datetime.strptime(x, '%m/%d/%Y')
RAW_CGM_DATA_P2 = pd.read_csv('CGMData670GPatient3.csv', parse_dates=['Date'], date_parser=mydateparser_P2)
RAW_CGM_DATA_P2 = RAW_CGM_DATA_P2[["Date", "Time", "Sensor Glucose (mg/dL)"]]  
RAW_CGM_DATA_P2['Time'] = pd.to_timedelta(RAW_CGM_DATA_P2["Time"])
RAW_CGM_DATA_P2['Date_Time'] = RAW_CGM_DATA_P2['Date'] + RAW_CGM_DATA_P2['Time']

total_rows_2_P2 = RAW_CGM_DATA_P2.shape[0]
index_2_P2=total_rows_2_P2-1
total_rows_3_P2 = MEAL_SORTED_INSULIN_DATA_P2.shape[0]
index_3_P2=total_rows_3_P2-1

CGM_MEAL_VECTOR_P2 = pd.DataFrame(columns=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29])
#CGM_MEAL_VECTOR = RAW_CGM_DATA[index_2-100:index_2-50]
#print(CGM_MEAL_VECTOR)

#print(MEAL_SORTED_INSULIN_DATA['Date_Time'][0])
y_P2 = MEAL_SORTED_INSULIN_DATA_P2['Date_Time'][0]
#print(y)
time_list_P2 = []
time_list_P2 = RAW_CGM_DATA_P2['Date_Time'].tolist()
time_list_P2.reverse()
#print(time_list)
glucose_list_P2 = RAW_CGM_DATA_P2['Sensor Glucose (mg/dL)'].tolist()
glucose_list_P2.reverse()
#print(glucose_list)
#print(len(time_list))
#print(len(glucose_list))


i = 0
for j in range(0,len(MEAL_SORTED_INSULIN_DATA_P2['Date_Time'])):
  y_P2 = MEAL_SORTED_INSULIN_DATA_P2['Date_Time'][j]
  temp_P2 = []
  while time_list_P2[i]<y_P2  and i<len(time_list_P2):
    i=i+1
  if i>=len(time_list_P2):
    break
  temp_P2 = glucose_list_P2[i-6:i+24]
  #if(time_list[i-5]>=y-required_time_30 and time_list[i+25]<=y+required_time_2):
  if(len(temp_P2)==30):
    CGM_MEAL_VECTOR_P2.loc[len(CGM_MEAL_VECTOR_P2), :] = temp_P2
  #print(CGM_MEAL_VECTOR)
  i = i+25
#print(CGM_MEAL_VECTOR)

CGM_MEAL_VECTOR_P2 = CGM_MEAL_VECTOR_P2.dropna()      
CGM_MEAL_VECTOR_P2 = CGM_MEAL_VECTOR_P2.reset_index(drop=True)
#print(CGM_MEAL_VECTOR_P2)
CGM_MEAL_VECTOR_P2 = CGM_MEAL_VECTOR_P2.head(n=200)
#print(CGM_MEAL_VECTOR_P2)


CGM_NO_MEAL_VECTOR_P2 = pd.DataFrame(columns=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23])
#CGM_MEAL_VECTOR = RAW_CGM_DATA[index_2-100:index_2-50]
#print(CGM_MEAL_VECTOR)

#print(NO_MEAL_SORTED_INSULIN_DATA_P2['Date_Time'][0])
y_1_P2 = NO_MEAL_SORTED_INSULIN_DATA_P2['Date_Time'][0]
#print(y_1_P2)
time_list_1_P2 = []
time_list_1_P2 = RAW_CGM_DATA_P2['Date_Time'].tolist()
time_list_1_P2.reverse()
#print(time_list_1_P2)
glucose_list_1_P2 = RAW_CGM_DATA_P2['Sensor Glucose (mg/dL)'].tolist()
glucose_list_1_P2.reverse()
#print(glucose_list_1_P2)
#print(len(time_list_1_P2))
#print(len(glucose_list_1_P2))

required_time_30_P2 = pd.to_timedelta('0 days 00:30:00')
required_time_2_P2 = pd.to_timedelta('0 days 02:00:00')
i = 0
for j in range(0,len(NO_MEAL_SORTED_INSULIN_DATA_P2['Date_Time'])):
  y_1_P2 = NO_MEAL_SORTED_INSULIN_DATA_P2['Date_Time'][j]
  temp_1_P2 = []
  while time_list_1_P2[i]<y_1_P2  and i<len(time_list_1_P2):
    i=i+1
  if i>=len(time_list_1_P2):
    break
  temp_1_P2 = glucose_list_1_P2[i:i+24]
  if(len(temp_1_P2)==24):
    CGM_NO_MEAL_VECTOR_P2.loc[len(CGM_NO_MEAL_VECTOR_P2), :] = temp_1_P2
  i = i+24
#print(CGM_NO_MEAL_VECTOR_P2)

CGM_NO_MEAL_VECTOR_P2 = CGM_NO_MEAL_VECTOR_P2.dropna()      
CGM_NO_MEAL_VECTOR_P2 = CGM_NO_MEAL_VECTOR_P2.reset_index(drop=True)
#print(CGM_NO_MEAL_VECTOR_P2)
CGM_NO_MEAL_VECTOR_P2 = CGM_NO_MEAL_VECTOR_P2.head(n=250)
#print(len(CGM_NO_MEAL_VECTOR_P2))

TOTAL_CGM_MEAL_VECTOR = CGM_MEAL_VECTOR_P1.append(CGM_MEAL_VECTOR_P2)
TOTAL_CGM_MEAL_VECTOR = TOTAL_CGM_MEAL_VECTOR.reset_index()
del TOTAL_CGM_MEAL_VECTOR['index']
TOTAL_CGM_MEAL_VECTOR = TOTAL_CGM_MEAL_VECTOR.drop(columns=[24,25,26,27,28,29], axis=1)
#print(TOTAL_CGM_MEAL_VECTOR.shape)

TOTAL_CGM_NO_MEAL_VECTOR = CGM_NO_MEAL_VECTOR_P1.append(CGM_NO_MEAL_VECTOR_P2)
TOTAL_CGM_NO_MEAL_VECTOR = TOTAL_CGM_NO_MEAL_VECTOR.reset_index()
del TOTAL_CGM_NO_MEAL_VECTOR['index']
#print(TOTAL_CGM_NO_MEAL_VECTOR.shape)

training = int(len(TOTAL_CGM_MEAL_VECTOR)*0.8)
testing = int(len(TOTAL_CGM_MEAL_VECTOR)*0.2)

TOTAL_CGM_MEAL_VECTOR_Training = TOTAL_CGM_MEAL_VECTOR[:training]
#print(len(TOTAL_CGM_MEAL_VECTOR_Training))

TOTAL_CGM_MEAL_VECTOR_Testing = TOTAL_CGM_MEAL_VECTOR[training: len(TOTAL_CGM_MEAL_VECTOR)]
#print(len(TOTAL_CGM_MEAL_VECTOR_Testing))

#TOTAL_CGM_MEAL_VECTOR_Testing.to_csv('test.csv', sep=',')

training = int(len(TOTAL_CGM_NO_MEAL_VECTOR)*0.8)

TOTAL_CGM_NO_MEAL_VECTOR_Training = TOTAL_CGM_NO_MEAL_VECTOR[:training]
#print(len(TOTAL_CGM_NO_MEAL_VECTOR_Training))

TOTAL_CGM_NO_MEAL_VECTOR_Testing = TOTAL_CGM_NO_MEAL_VECTOR[training: len(TOTAL_CGM_NO_MEAL_VECTOR)]
##print(len(TOTAL_CGM_NO_MEAL_VECTOR_Testing))

#TOTAL_CGM_NO_MEAL_VECTOR_Testing.to_csv('test_1.csv', sep=',')

pd.concat([TOTAL_CGM_MEAL_VECTOR_Testing,TOTAL_CGM_NO_MEAL_VECTOR_Testing]).to_csv('test_1.csv')

Feature_Matrix_Meal_Data = pd.DataFrame() 
 
# Feature 1 - Windowed Mean (for 30 min interval)
win_size=6
total_vals = TOTAL_CGM_MEAL_VECTOR_Training.shape[1]-win_size
for index in range(0, total_vals, win_size):
    dm = TOTAL_CGM_MEAL_VECTOR_Training.iloc[:, index:index + win_size].mean(axis=1)
    Feature_Matrix_Meal_Data['Mean ' + str(index)] = dm

#Feature_Matrix_Meal_Data = Feature_Matrix_Meal_Data.drop('Mean ' + str(index), axis=1)
#print(Feature_Matrix_Meal_Data.shape)

    
# Feature 2 - Windowed Standard Deviation (for 30 min interval)
win_size=6
total_vals = TOTAL_CGM_MEAL_VECTOR_Training.shape[1]-win_size
for index in range(0, total_vals, win_size):
    dstd = TOTAL_CGM_MEAL_VECTOR_Training.iloc[:, index:index + win_size].std(axis=1)
    Feature_Matrix_Meal_Data['Std_deviation ' + str(index)] = dstd

#Feature_Matrix_Meal_Data = Feature_Matrix_Meal_Data.drop('Std_deviation ' + str(index), axis=1)        
#print(Feature_Matrix_Meal_Data.shape)
    
    
# Feature 3 - Fast Fourier Transform
FFT = pd.DataFrame()
def calculate_fft_vals(series):
    FFT_abs = abs(fft(series))
    FFT_abs.sort()
    return np.flip(FFT_abs)[0:8]

FFT['FFT_vals'] = TOTAL_CGM_MEAL_VECTOR_Training.apply(lambda series: calculate_fft_vals(series), axis=1)
FFT_Vals= pd.DataFrame(FFT.FFT_vals.tolist(), columns=['FFT1', 'FFT2', 'FFT3', 'FFT4', 'FFT5', 'FFT6', 'FFT7','FFT8'],index=FFT.FFT_vals.index)
Feature_Matrix_Meal_Data = pd.concat([Feature_Matrix_Meal_Data,FFT_Vals],axis=1)
    
#print(Feature_Matrix_Meal_Data.shape)
    
 
# Feature 4 - Max of CGM Velocity 
    
Velocity_Data = pd.DataFrame()
win_size=6
total_vals=TOTAL_CGM_MEAL_VECTOR_Training.shape[1]-win_size

for index in range(0, total_vals):
    dv = TOTAL_CGM_MEAL_VECTOR_Training.iloc[:, index + win_size] - TOTAL_CGM_MEAL_VECTOR_Training.iloc[:, index]
    Velocity_Data['vel'+str(index)] = dv

Feature_Matrix_Meal_Data['Max CGM Vel']=Velocity_Data.max(axis = 1,skipna=True)
    
#print(Feature_Matrix_Meal_Data.shape)
   
    
# Feature 5 - Skewness
def calculate_skewness(series):
    series_counts = series.value_counts()
    skewness_vals = skew(series_counts)
    return skewness_vals

Feature_Matrix_Meal_Data['skewness'] = TOTAL_CGM_MEAL_VECTOR_Training.apply(lambda row: calculate_skewness(row), axis=1)
    
#print(Feature_Matrix_Meal_Data.shape)

Feature_Matrix_No_Meal_Data = pd.DataFrame() 
   
# Feature 1 - Windowed Mean (for 30 min interval)
win_size=6
total_vals = TOTAL_CGM_NO_MEAL_VECTOR_Training.shape[1]-win_size
for index in range(0, total_vals, win_size):
    dm = TOTAL_CGM_NO_MEAL_VECTOR_Training.iloc[:, index:index + win_size].mean(axis=1)
    Feature_Matrix_No_Meal_Data['Mean ' + str(index)] = dm

#print(Feature_Matrix_No_Meal_Data.shape)

    
# Feature 2 - Windowed Standard Deviation (for 30 min interval)
win_size=6
total_vals = TOTAL_CGM_NO_MEAL_VECTOR_Training.shape[1]-win_size
for index in range(0, total_vals, win_size):
    dstd = TOTAL_CGM_NO_MEAL_VECTOR_Training.iloc[:, index:index + win_size].std(axis=1)
    Feature_Matrix_No_Meal_Data['Std_deviation ' + str(index)] = dstd
        
#print(Feature_Matrix_No_Meal_Data.shape)
 
    
# Feature 3 - Fast Fourier Transform
FFT = pd.DataFrame()
def calculate_fft_vals(series):
    FFT_abs = abs(fft(series))
    FFT_abs.sort()
    return np.flip(FFT_abs)[0:8]

FFT['FFT_vals'] = TOTAL_CGM_NO_MEAL_VECTOR_Training.apply(lambda series: calculate_fft_vals(series), axis=1)
FFT_Vals= pd.DataFrame(FFT.FFT_vals.tolist(), columns=['FFT1', 'FFT2', 'FFT3', 'FFT4', 'FFT5', 'FFT6', 'FFT7','FFT8'],index=FFT.FFT_vals.index)
Feature_Matrix_No_Meal_Data = pd.concat([Feature_Matrix_No_Meal_Data,FFT_Vals],axis=1)
    
#print(Feature_Matrix_No_Meal_Data.shape)
    
    
# Feature 4 - Max of CGM Velocity 
Velocity_Data = pd.DataFrame()
win_size=6
total_vals=TOTAL_CGM_NO_MEAL_VECTOR_Training.shape[1]-win_size

for index in range(0, total_vals):
    dv = TOTAL_CGM_NO_MEAL_VECTOR_Training.iloc[:, index + win_size] - TOTAL_CGM_NO_MEAL_VECTOR_Training.iloc[:, index]
    Velocity_Data['vel'+str(index)] = dv

Feature_Matrix_No_Meal_Data['Max CGM Vel']=Velocity_Data.max(axis = 1,skipna=True)
    
#print(Feature_Matrix_No_Meal_Data.shape)
 
    
# Feature 5 - Skewness
def calculate_skewness(series):
    series_counts = series.value_counts()
    skewness_vals = skew(series_counts)
    return skewness_vals

Feature_Matrix_No_Meal_Data['skewness'] = TOTAL_CGM_NO_MEAL_VECTOR_Training.apply(lambda row: calculate_skewness(row), axis=1)
    
#print(Feature_Matrix_No_Meal_Data.shape)

Feature_Matrix = pd.DataFrame()
Feature_Matrix = pd.concat([Feature_Matrix_Meal_Data, Feature_Matrix_No_Meal_Data])
pd.set_option('display.max_rows', Feature_Matrix.shape[0]+1)
#print(Feature_Matrix.shape)
#Feature_Matrix.head(5)

# Standardize feature matrix
Feature_Matrix = StandardScaler().fit_transform(Feature_Matrix)
#print(Feature_Matrix)

  #Class labels 
Class_labels = np.append(np.ones(len(Feature_Matrix_Meal_Data)),np.zeros(len(Feature_Matrix_No_Meal_Data)))
#print(Class_labels)

# Training KNN Model
    
print("--------KNN MODELS-----------")    
X_train, X_test, y_train, y_test = train_test_split(Feature_Matrix, Class_labels, test_size=0.2, random_state=4)
    
K = 5 
for n in range(1,K+1):
    neighbours = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)
    yhat=neighbours.predict(X_test)
    skfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=777 )
    scores = cross_validate(neighbours, Feature_Matrix, Class_labels, cv=skfold,
                            scoring=('accuracy', 'precision','recall','f1'),
                              return_train_score=True)   
    print("For KNN with K value:"+str(n))
    print("Accuracy:",scores['test_accuracy'].mean(), 
          "Precision:",scores['test_precision'].mean(),
          "Recall:",scores['test_recall'].mean(),
          "F1 Measure:",scores['test_f1'].mean())
    neighbours.fit(Feature_Matrix, Class_labels)
    handler = open("KNN"+str(n)+".model","wb")
    pickle.dump(neighbours,handler)
    handler.close()
       
    
#Training SVC model
print("--------SVM MODEL-----------") 
svc = SVC(gamma='auto',random_state=777)
skfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=777 )
scores = cross_validate(svc, Feature_Matrix, Class_labels, cv=skfold,
                        scoring=('accuracy', 'precision','recall','f1'),
                        return_train_score=True)   
print("Accuracy:",scores['test_accuracy'].mean(), 
      "Precision:",scores['test_precision'].mean(),
      "Recall:",scores['test_recall'].mean(),
      "F1 Measure:",scores['test_f1'].mean())
svc.fit(Feature_Matrix, Class_labels)
handler = open("SVC.model","wb")
pickle.dump(svc,handler)
handler.close()



